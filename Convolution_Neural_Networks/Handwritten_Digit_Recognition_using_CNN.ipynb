{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Megha_Komarraju_Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqyVbCyKfjDe",
        "outputId": "3c20c89e-fe25-4b4d-97f8-d62d374ff2cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Connecting to google drive to access the files\n",
        "from google.colab import drive,files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G91HMTOEf3Md",
        "outputId": "df95f5b4-7d26-4582-d333-ae869d3f4940",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating a CNN model for 10 class digital recognition problem\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MyCNNNetwork(nn.Module):\n",
        "#defining network model\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, kernel_size=(5,5))\n",
        "    self.pool=nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6,16,kernel_size=(5,5))\n",
        "    self.fc1 = nn.Linear(16*4*4,120)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3=nn.Linear(84,10)\n",
        "\n",
        "\n",
        "#defining forward method\n",
        "  def forward(self,x):\n",
        "    x=self.pool(F.relu(self.conv1(x)))\n",
        "    x=self.pool(F.relu(self.conv2(x)))\n",
        "    x=x.view(-1,self.num_flat_features(x))\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=F.log_softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "#falttening features to send as input to Fully COnnected Feed Forward Network\n",
        "  def num_flat_features(self,x):\n",
        "    size=x.size()[1:]\n",
        "    num_features=1\n",
        "    for s in size:\n",
        "      num_features*=s\n",
        "    return num_features\n",
        "\n",
        "\n",
        "#Printing the network structure\n",
        "net=MyCNNNetwork().to(device)\n",
        "print(net)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCNNNetwork(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DOqVHZmgtQa",
        "outputId": "3e1df88a-02ff-469b-985c-55e572fc88a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params=list(net.parameters())\n",
        "for i in range(len(params)):\n",
        "  print(params[i].size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 1, 5, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([16, 6, 5, 5])\n",
            "torch.Size([16])\n",
            "torch.Size([120, 256])\n",
            "torch.Size([120])\n",
            "torch.Size([84, 120])\n",
            "torch.Size([84])\n",
            "torch.Size([10, 84])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ejYfHG8oKb3"
      },
      "source": [
        "# define a customised dataset in torch\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "#overriding : __init__,__len__, and __getitem__ methods\n",
        "\n",
        "class MNISTDatasets(Dataset):\n",
        "\n",
        "  def __init__(self,dir,transform=None):\n",
        "    self.dir=dir # for example: /content/drive/My Drive/trainingset/1 \n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    files=glob.glob(self.dir+'/*.jpg')[:1000]\n",
        "    return len(files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx=idx.tolist()\n",
        "\n",
        "    all_files=glob.glob(self.dir+'/*.jpg')[:1000]\n",
        "    img_fname=os.path.join(self.dir,all_files[idx])\n",
        "    image=io.imread(img_fname)\n",
        "\n",
        "    digit=int(self.dir.split('/')[-1].strip())\n",
        "    label=np.array(digit)\n",
        "    \n",
        "    sample={'image':image,'label':label}\n",
        "\n",
        "    if self.transform:\n",
        "      instance=self.transform(sample)   \n",
        "    \n",
        "    return instance\n",
        "\n",
        " "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua9k6hXJpGO7"
      },
      "source": [
        "#cutomised transformation with several operations:\n",
        "# Rescale, ToTensor\n",
        "from skimage import transform\n",
        "from torchvision import transforms,utils\n",
        "\n",
        "class Rescale(object):\n",
        "\n",
        "  def __init__(self,output_size):\n",
        "    assert isinstance(output_size,(int,tuple))\n",
        "    self.output_size=output_size\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    image,label=sample['image'],sample['label']    \n",
        "    h,w=image.shape[-2:]\n",
        "\n",
        "\n",
        "    if isinstance(self.output_size,int):\n",
        "      if h>w:\n",
        "        new_h,new_w=self.output_size*h/w,self.output_size\n",
        "      else:\n",
        "          new_h,new_w=self.output_size,self.output_size*w/h\n",
        "    else:\n",
        "      new_h,new_w=self.output_size\n",
        "    \n",
        "    new_h,new_w=int(new_h),int(new_w)\n",
        "\n",
        "    new_img=transform.resize(image,(new_h,new_w))\n",
        "    \n",
        "    return {'image':new_img,'label':label}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    image,label=sample['image'],sample['label']\n",
        "\n",
        "    image=image.reshape((1,image.shape[0],image.shape[1]))\n",
        "\n",
        "    \n",
        "    return {'image':torch.from_numpy(image),'label':torch.from_numpy(label)}\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCYhiSWOtRkf",
        "outputId": "41cfb768-4e38-4ba9-b625-f4c176242c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "batch_size=32\n",
        "\n",
        "list_datasets=[]\n",
        "for i in range(10):\n",
        "\n",
        "  cur_ds=MNISTDatasets(dir='/content/drive/My Drive/trainingset/'+str(i),transform=transforms.Compose([Rescale(28),ToTensor()]))\n",
        "  list_datasets.append(cur_ds)\n",
        "\n",
        "dataset=torch.utils.data.ConcatDataset(list_datasets)\n",
        "print(len(dataset))\n",
        "\n",
        "train_size=int(len(dataset)*0.7)\n",
        "val_size=len(dataset)-train_size\n",
        "train_dataset,val_dataset=random_split(dataset,[train_size,val_size])\n",
        "\n",
        "train_loader=DataLoader(train_dataset,batch_size,shuffle=True,num_workers=1)\n",
        "val_loader=DataLoader(val_dataset,batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je37L-iKvpHQ",
        "outputId": "0abb8f3e-261e-4a9c-d798-0ceb0954e8f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Training code\n",
        "\n",
        "epochs=5\n",
        "learning_rate=1e-2\n",
        "optimizer=optim.Adam(net.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  net.train()\n",
        "\n",
        "  running_loss=0.0\n",
        "  \n",
        "  for i,batch in enumerate(train_loader):\n",
        "    inputs,targets=batch['image'].to(device,dtype=torch.float),batch['label'].to(device,dtype=torch.long)\n",
        "    optimizer.zero_grad()\n",
        "    predicted_outputs=net(inputs)\n",
        "    loss=criterion(predicted_outputs,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss+=loss.item()\n",
        "    #training loss for every 10 batches\n",
        "    if(i+1)%10==0:\n",
        "      print('epoch %d,batch: %d,training loss: %.3f' % (epoch+1,i+1,running_loss/10))\n",
        "      running_loss=0.0\n",
        "\n",
        "#validation code\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  correct=[0.0]*10\n",
        "  total=[0.]*10\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for b,data in enumerate(val_loader):\n",
        "      images,labels=data['image'].to(device,dtype=torch.float),data['label'].to(device,dtype=torch.long)\n",
        "      predicted_outputs=net(images)\n",
        "      _,predicted=torch.max(predicted_outputs,1)\n",
        "      c=(predicted==labels)\n",
        "      for i in range(len(labels)):\n",
        "        label=labels[i]\n",
        "        correct[label]+=c[i].item()\n",
        "        total[label]+=1\n",
        "#accuracy for the entire validation set per epochh\n",
        "  for i in range(10):\n",
        "        print('\\tValidation accuracy for digit %d:%.2f'% (i,100*correct[i]/total[i]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1,batch: 10,training loss: 2.191\n",
            "epoch 1,batch: 20,training loss: 1.638\n",
            "epoch 1,batch: 30,training loss: 1.089\n",
            "epoch 1,batch: 40,training loss: 0.706\n",
            "epoch 1,batch: 50,training loss: 0.551\n",
            "epoch 1,batch: 60,training loss: 0.567\n",
            "epoch 1,batch: 70,training loss: 0.440\n",
            "epoch 1,batch: 80,training loss: 0.378\n",
            "epoch 1,batch: 90,training loss: 0.490\n",
            "epoch 1,batch: 100,training loss: 0.345\n",
            "epoch 1,batch: 110,training loss: 0.324\n",
            "epoch 1,batch: 120,training loss: 0.375\n",
            "epoch 1,batch: 130,training loss: 0.315\n",
            "epoch 1,batch: 140,training loss: 0.219\n",
            "epoch 1,batch: 150,training loss: 0.273\n",
            "epoch 1,batch: 160,training loss: 0.251\n",
            "epoch 1,batch: 170,training loss: 0.220\n",
            "epoch 1,batch: 180,training loss: 0.216\n",
            "epoch 1,batch: 190,training loss: 0.194\n",
            "epoch 1,batch: 200,training loss: 0.293\n",
            "epoch 1,batch: 210,training loss: 0.252\n",
            "\tValidation accuracy for digit 0:98.34\n",
            "\tValidation accuracy for digit 1:94.62\n",
            "\tValidation accuracy for digit 2:89.71\n",
            "\tValidation accuracy for digit 3:94.81\n",
            "\tValidation accuracy for digit 4:94.90\n",
            "\tValidation accuracy for digit 5:71.20\n",
            "\tValidation accuracy for digit 6:98.77\n",
            "\tValidation accuracy for digit 7:94.93\n",
            "\tValidation accuracy for digit 8:94.01\n",
            "\tValidation accuracy for digit 9:92.98\n",
            "epoch 2,batch: 10,training loss: 0.201\n",
            "epoch 2,batch: 20,training loss: 0.116\n",
            "epoch 2,batch: 30,training loss: 0.116\n",
            "epoch 2,batch: 40,training loss: 0.131\n",
            "epoch 2,batch: 50,training loss: 0.179\n",
            "epoch 2,batch: 60,training loss: 0.110\n",
            "epoch 2,batch: 70,training loss: 0.178\n",
            "epoch 2,batch: 80,training loss: 0.103\n",
            "epoch 2,batch: 90,training loss: 0.204\n",
            "epoch 2,batch: 100,training loss: 0.213\n",
            "epoch 2,batch: 110,training loss: 0.177\n",
            "epoch 2,batch: 120,training loss: 0.180\n",
            "epoch 2,batch: 130,training loss: 0.179\n",
            "epoch 2,batch: 140,training loss: 0.163\n",
            "epoch 2,batch: 150,training loss: 0.193\n",
            "epoch 2,batch: 160,training loss: 0.154\n",
            "epoch 2,batch: 170,training loss: 0.177\n",
            "epoch 2,batch: 180,training loss: 0.130\n",
            "epoch 2,batch: 190,training loss: 0.097\n",
            "epoch 2,batch: 200,training loss: 0.121\n",
            "epoch 2,batch: 210,training loss: 0.159\n",
            "\tValidation accuracy for digit 0:99.67\n",
            "\tValidation accuracy for digit 1:97.13\n",
            "\tValidation accuracy for digit 2:94.21\n",
            "\tValidation accuracy for digit 3:91.88\n",
            "\tValidation accuracy for digit 4:98.64\n",
            "\tValidation accuracy for digit 5:95.57\n",
            "\tValidation accuracy for digit 6:95.69\n",
            "\tValidation accuracy for digit 7:95.61\n",
            "\tValidation accuracy for digit 8:96.13\n",
            "\tValidation accuracy for digit 9:87.72\n",
            "epoch 3,batch: 10,training loss: 0.102\n",
            "epoch 3,batch: 20,training loss: 0.112\n",
            "epoch 3,batch: 30,training loss: 0.094\n",
            "epoch 3,batch: 40,training loss: 0.121\n",
            "epoch 3,batch: 50,training loss: 0.163\n",
            "epoch 3,batch: 60,training loss: 0.126\n",
            "epoch 3,batch: 70,training loss: 0.069\n",
            "epoch 3,batch: 80,training loss: 0.097\n",
            "epoch 3,batch: 90,training loss: 0.104\n",
            "epoch 3,batch: 100,training loss: 0.055\n",
            "epoch 3,batch: 110,training loss: 0.203\n",
            "epoch 3,batch: 120,training loss: 0.109\n",
            "epoch 3,batch: 130,training loss: 0.121\n",
            "epoch 3,batch: 140,training loss: 0.168\n",
            "epoch 3,batch: 150,training loss: 0.114\n",
            "epoch 3,batch: 160,training loss: 0.148\n",
            "epoch 3,batch: 170,training loss: 0.102\n",
            "epoch 3,batch: 180,training loss: 0.132\n",
            "epoch 3,batch: 190,training loss: 0.103\n",
            "epoch 3,batch: 200,training loss: 0.080\n",
            "epoch 3,batch: 210,training loss: 0.185\n",
            "\tValidation accuracy for digit 0:98.01\n",
            "\tValidation accuracy for digit 1:97.13\n",
            "\tValidation accuracy for digit 2:96.14\n",
            "\tValidation accuracy for digit 3:94.16\n",
            "\tValidation accuracy for digit 4:95.92\n",
            "\tValidation accuracy for digit 5:95.25\n",
            "\tValidation accuracy for digit 6:99.38\n",
            "\tValidation accuracy for digit 7:95.61\n",
            "\tValidation accuracy for digit 8:90.14\n",
            "\tValidation accuracy for digit 9:96.14\n",
            "epoch 4,batch: 10,training loss: 0.084\n",
            "epoch 4,batch: 20,training loss: 0.100\n",
            "epoch 4,batch: 30,training loss: 0.122\n",
            "epoch 4,batch: 40,training loss: 0.111\n",
            "epoch 4,batch: 50,training loss: 0.103\n",
            "epoch 4,batch: 60,training loss: 0.129\n",
            "epoch 4,batch: 70,training loss: 0.100\n",
            "epoch 4,batch: 80,training loss: 0.147\n",
            "epoch 4,batch: 90,training loss: 0.102\n",
            "epoch 4,batch: 100,training loss: 0.112\n",
            "epoch 4,batch: 110,training loss: 0.126\n",
            "epoch 4,batch: 120,training loss: 0.098\n",
            "epoch 4,batch: 130,training loss: 0.083\n",
            "epoch 4,batch: 140,training loss: 0.087\n",
            "epoch 4,batch: 150,training loss: 0.089\n",
            "epoch 4,batch: 160,training loss: 0.154\n",
            "epoch 4,batch: 170,training loss: 0.092\n",
            "epoch 4,batch: 180,training loss: 0.142\n",
            "epoch 4,batch: 190,training loss: 0.107\n",
            "epoch 4,batch: 200,training loss: 0.108\n",
            "epoch 4,batch: 210,training loss: 0.068\n",
            "\tValidation accuracy for digit 0:98.01\n",
            "\tValidation accuracy for digit 1:99.64\n",
            "\tValidation accuracy for digit 2:98.71\n",
            "\tValidation accuracy for digit 3:97.40\n",
            "\tValidation accuracy for digit 4:97.96\n",
            "\tValidation accuracy for digit 5:95.25\n",
            "\tValidation accuracy for digit 6:98.46\n",
            "\tValidation accuracy for digit 7:89.86\n",
            "\tValidation accuracy for digit 8:89.44\n",
            "\tValidation accuracy for digit 9:93.68\n",
            "epoch 5,batch: 10,training loss: 0.061\n",
            "epoch 5,batch: 20,training loss: 0.039\n",
            "epoch 5,batch: 30,training loss: 0.110\n",
            "epoch 5,batch: 40,training loss: 0.171\n",
            "epoch 5,batch: 50,training loss: 0.082\n",
            "epoch 5,batch: 60,training loss: 0.065\n",
            "epoch 5,batch: 70,training loss: 0.035\n",
            "epoch 5,batch: 80,training loss: 0.109\n",
            "epoch 5,batch: 90,training loss: 0.095\n",
            "epoch 5,batch: 100,training loss: 0.068\n",
            "epoch 5,batch: 110,training loss: 0.071\n",
            "epoch 5,batch: 120,training loss: 0.083\n",
            "epoch 5,batch: 130,training loss: 0.126\n",
            "epoch 5,batch: 140,training loss: 0.083\n",
            "epoch 5,batch: 150,training loss: 0.156\n",
            "epoch 5,batch: 160,training loss: 0.117\n",
            "epoch 5,batch: 170,training loss: 0.135\n",
            "epoch 5,batch: 180,training loss: 0.097\n",
            "epoch 5,batch: 190,training loss: 0.065\n",
            "epoch 5,batch: 200,training loss: 0.083\n",
            "epoch 5,batch: 210,training loss: 0.117\n",
            "\tValidation accuracy for digit 0:100.00\n",
            "\tValidation accuracy for digit 1:96.42\n",
            "\tValidation accuracy for digit 2:96.46\n",
            "\tValidation accuracy for digit 3:97.40\n",
            "\tValidation accuracy for digit 4:98.30\n",
            "\tValidation accuracy for digit 5:96.52\n",
            "\tValidation accuracy for digit 6:97.54\n",
            "\tValidation accuracy for digit 7:95.95\n",
            "\tValidation accuracy for digit 8:89.08\n",
            "\tValidation accuracy for digit 9:92.28\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
