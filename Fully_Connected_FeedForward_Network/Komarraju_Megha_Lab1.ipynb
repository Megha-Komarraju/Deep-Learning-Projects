{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_using_FCFFN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rce5HFAgBs6y",
        "outputId": "7c789a19-9480-4c2d-df2a-2312290767d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# load text data and convert the label/sentiment into corresponding numeric values: \n",
        "# possible packages you might need are: pandas, numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# read the training data\n",
        "fname='facebook_comments.csv'\n",
        "df_train=pd.read_csv(fname,header=None,names=['text','sentiment'],encoding='iso-8859-1',lineterminator='\\n')\n",
        "sentiment_dict={'positive':2,'neutral':1,'negative':0}\n",
        "df_train['labels']=df_train['sentiment'].str.strip().map(sentiment_dict)\n",
        "# get texts and labels\n",
        "training_texts=df_train.text.values\n",
        "labels=df_train.labels.values\n",
        "# show the first 5 records\n",
        "df_train.head()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  labels\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjQ1Z_c7FEuK",
        "outputId": "5c98b1f2-1432-460b-c766-01c625489942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Preprocess dat\n",
        "# preprocess the loaded textual data, including removing stopwords, stemming, and tok\n",
        "# represent each document (i.e., comment) using TF-IDF strategy. The features are the\n",
        "# possible packages you might need are: scikit-learn, numpy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# tokenize and create a document-feature matrix X and a label vector Y\n",
        "vectorizer=TfidfVectorizer(stop_words='english',max_features=1000)\n",
        "instances=vectorizer.fit_transform(training_texts)\n",
        "X=instances\n",
        "Y=np.array(labels)\n",
        "\n",
        "# print out the shape of X and Y\n",
        "print(X.shape,',',Y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 1000) , (1999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7mEiomkJr_G"
      },
      "source": [
        "#Traditional Machine Learning Models: Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edEvTYH0DkGf",
        "outputId": "417e1ad0-9c14-4fdc-c5df-87ffcf0abcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Random Forest - mean: 64.1332% (std: +/- 2.0919%)\n",
        "# using 10-fold cross-validation to show the prediction accuracy\n",
        "# possible packages you might need are: scikit-learn, numpy\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "kfold=KFold(n_splits=10,shuffle=True,random_state=2020)\n",
        "rf_model=RandomForestClassifier(random_state=2020,max_depth=2,criterion='entropy')\n",
        "rf_cvscores=[]\n",
        "\n",
        "for train,test in kfold.split(X):\n",
        "  rf_model.fit(X[train],Y[train])\n",
        "  rf_acc=rf_model.score(X[test],Y[test])\n",
        "  rf_cvscores.append(rf_acc)\n",
        "\n",
        "print(\"Random Forest - mean: %.4f%% (std: +/- %.4f%%)\" % (np.mean(rf_cvscores)*100, np.std(rf_cvscores)*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest - mean: 64.1332% (std: +/- 2.0919%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpG77Ep5Jn7i"
      },
      "source": [
        "#Fully connected feedforward Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNc09ikbJYxB"
      },
      "source": [
        "# Design your own network with the following requirements:\n",
        "# 1. Having dropout\n",
        "# 2. Separate the dataset into training and validation (80-20%)\n",
        "# 3. The prediction accuracy on the validation set should be at least 50% for this 3-\n",
        "# possible packages you might need are: scikit-learn, numpy, torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ie8ITA0KcdH"
      },
      "source": [
        "Build the train loader and validation loader\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCPgq0azKYJn"
      },
      "source": [
        "# convert your numpy array to TensorDataset and create a data loader for training and\n",
        "# some hyperparameters: input dimension, output dimension, batch size, number of epoch\n",
        "epochs = 15\n",
        "lr = 1e-3\n",
        "indim = X.shape[1]\n",
        "outdim = 3\n",
        "drate = 0.6\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "X_tensor=torch.from_numpy(X.toarray())\n",
        "Y_tensor=torch.from_numpy(Y)\n",
        "\n",
        "dataset=TensorDataset(X_tensor,Y_tensor)\n",
        "train_size=int(0.8*len(dataset))\n",
        "validation_size=len(dataset)-train_size\n",
        "train_dataset,validation_dataset=torch.utils.data.random_split(dataset,[train_size,validation_size])\n",
        "\n",
        "#create training loader and validation loader\n",
        "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "val_loader=DataLoader(validation_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y9Tjf9bKtzr",
        "outputId": "eff0ae64-0c0d-4663-a102-a1c9fafca55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# create your model/network\n",
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, dropout_rate):\n",
        "    \n",
        "    super(SentimentNetwork,self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim,100)\n",
        "    self.dropout = nn.Dropout(dropout_rate) \n",
        "    self.fc2 = nn.Linear(100,50)\n",
        "    self.fc3 = nn.Linear(50,output_dim)\n",
        "\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=self.dropout(x)\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=F.log_softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "# create a model\n",
        "model = SentimentNetwork(indim,outdim,drate)\n",
        "print(model)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNetwork(\n",
            "  (fc1): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (dropout): Dropout(p=0.6, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TvDen1IM7Ks"
      },
      "source": [
        "Create a training function to train the model and an evaluation function to evaluate the performance on the separate validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9cIvqo1YD-g"
      },
      "source": [
        "# define a training process function\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "  epoch_loss, epoch_acc = 0.0,0.0 # the loss and accuracy for each epoch\n",
        "  correct_pre=0\n",
        "  cum_los=0\n",
        "  loss_values=[]\n",
        "  # correct,log_interval=0,4\n",
        "  model.train()\n",
        "  total=0\n",
        "  for i,(data, target) in enumerate(train_loader):   \n",
        "    epoch_loss, epoch_acc = 0.0,0.0\n",
        "    # Clearing gradients w.r.t. parameters\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass to get output\n",
        "    output = model(data.float())\n",
        "\n",
        "    # Calculating Loss using cross entropy \n",
        "    loss = criterion(output, target)       \n",
        "    epoch_loss = loss.item()\n",
        "    cum_los=cum_los+epoch_loss \n",
        "\n",
        "    # Back propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating parameters\n",
        "    optimizer.step()\n",
        "    epoch_acc = (output.argmax(1) == target).sum().item()\n",
        "    correct_pre=correct_pre+epoch_acc\n",
        "    total=total+len(data)   \n",
        "  return cum_los/len(train_loader), correct_pre/total\n",
        "   \n",
        "\n",
        "## evaluation part\n",
        "def evaluate(model, val_loader, criterion):\n",
        "  epoch_loss, epoch_acc = 0.0,0.0 # the loss and accuracy for each epoch\n",
        "  correct_pre_val=0\n",
        "  cum_los_val=0\n",
        "  total_val=0\n",
        "  model.eval()\n",
        "  for data, target in val_loader:\n",
        "    with torch.no_grad():\n",
        "      # Forward pass to get output\n",
        "      output = model(data.float())\n",
        "      # Calculating Loss using cross entropy \n",
        "      epoch_loss = criterion(output, target).item()\n",
        "      cum_los_val=cum_los_val+epoch_loss\n",
        "      # Calculating accuracy\n",
        "      epoch_acc = (output.argmax(1) == target).sum().item()\n",
        "      correct_pre_val=correct_pre_val+epoch_acc  \n",
        "      total_val=total_val+len(data)\n",
        "  return cum_los_val/len(val_loader), correct_pre_val/total_val\n",
        "\n",
        "   "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0T2tI4Aqt03"
      },
      "source": [
        "Main starting point: train the model and evaluate the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRkqk0lKquxz",
        "outputId": "c237000f-3a92-4015-a4ba-371194e4ff4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "# define the loss function and optimizer\n",
        "optimizer=optim.Adam(model.parameters(),lr=lr)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "# real training and evaluation process\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.4f} |  Val. Acc: {valid_acc:.4f}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.8761 | Train Acc: 0.6316\n",
            "\t Val. Loss: 0.7840 |  Val. Acc: 0.6225\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.6372 | Train Acc: 0.6992\n",
            "\t Val. Loss: 0.5479 |  Val. Acc: 0.7975\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.4249 | Train Acc: 0.8487\n",
            "\t Val. Loss: 0.4098 |  Val. Acc: 0.8425\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.3251 | Train Acc: 0.8787\n",
            "\t Val. Loss: 0.3606 |  Val. Acc: 0.8450\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.2672 | Train Acc: 0.8974\n",
            "\t Val. Loss: 0.3139 |  Val. Acc: 0.8550\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.2183 | Train Acc: 0.9087\n",
            "\t Val. Loss: 0.2630 |  Val. Acc: 0.8650\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.1847 | Train Acc: 0.9156\n",
            "\t Val. Loss: 0.2248 |  Val. Acc: 0.8850\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.1433 | Train Acc: 0.9500\n",
            "\t Val. Loss: 0.1903 |  Val. Acc: 0.9250\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.1068 | Train Acc: 0.9725\n",
            "\t Val. Loss: 0.1737 |  Val. Acc: 0.9300\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.0879 | Train Acc: 0.9850\n",
            "\t Val. Loss: 0.1506 |  Val. Acc: 0.9600\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.0767 | Train Acc: 0.9856\n",
            "\t Val. Loss: 0.1536 |  Val. Acc: 0.9575\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.0603 | Train Acc: 0.9900\n",
            "\t Val. Loss: 0.1546 |  Val. Acc: 0.9600\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.0521 | Train Acc: 0.9912\n",
            "\t Val. Loss: 0.1600 |  Val. Acc: 0.9650\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.0487 | Train Acc: 0.9906\n",
            "\t Val. Loss: 0.1574 |  Val. Acc: 0.9600\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.0400 | Train Acc: 0.9937\n",
            "\t Val. Loss: 0.1607 |  Val. Acc: 0.9650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xrvKu_83hxm"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}
